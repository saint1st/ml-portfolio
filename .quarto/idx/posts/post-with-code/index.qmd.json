{"title":"Gradient Descent, how does it work?","markdown":{"yaml":{"title":"Gradient Descent, how does it work?","author":"Darkhan Islam","date":"2024-10-26","categories":["theory","code"],"image":"gd.gif","listing":{"categories":true,"contents":"posts","type":"grid","sort":"date desc","fields":["image","title","date","categories","description","reading-time"],"feed":true,"filter-ui":true},"page-layout":"article"},"headingText":"Problem Statement","containsRefs":false,"markdown":"\n\nGradient Descent is a method for unconstrained math optimization. It is a **first order**\niterative algorithm for minimizing differentiable multivariate function.\nThe key idea is to take repeated steps in the opposite direction of the gradient of the function at the current point,\nbecause this is a direction of steepest descent. --> Conversely, stepping in the direction of\nthe gradient will lead to a trajectory that maximizes that function, the procedure is\nthen know as **gradient ascent**\n\n![](gd.jpeg){width=1200px}\n\nIn this tutorial we will automate the process of optimizing $w$ and $b$ usig gradient descent\n\n\n```python\nimport math, copy\nimport numpy as np\nimport matplotlib.pyplot as plt\n```\n\n\nLet's use the same two data points as before - a house with 1000 square feet sold for \\\\$300,000 and a house with 2000 square feet sold for \\\\$500,000.\n\n| Size (1000 sqft)     | Price (1000s of dollars) |\n| ----------------| ------------------------ |\n| 1               | 300                      |\n| 2               | 500                      |\n\n\n```python\nx_train = np.array([1.0, 2.0])\ny_train = np.array([300.0, 500.0])\n```\n\n## Define cost function\nWe consider a linear model that predicts $f_{w,b}(x^{(i)})$:\n$$f_{w,b}(x^{(i)}) = wx^{(i)} + b \\tag{1}$$\nIn linear regression, we utilize input training data to fit the parameters $w$,$b$ by minimizing\na measure of the error between our predictions $f_{w,b}(x^{(i)})$ and the actual data $y^{(i)}$.\nThe measure is called the $cost$, $J(w,b)$. In training we measure the cost over all of our training\nsamples $x^{(i)},y^{(i)}$\n$$J(w,b) = \\frac{1}{2m} \\sum\\limits_{i = 0}^{m-1} (f_{w,b}(x^{(i)}) - y^{(i)})^2\\tag{2}$$\n\nLet's define cost function described above.\n\n```python\ndef compute_cost(x, y, w, b):\n    m = x.shape[0]\n    cost = 0\n\n    for i in range(m):\n        f_wb = w * x[i] + b\n        cost = cost + (f_wb - y[i])**2\n    total_cost = 1 / (2 * m) * cost\n    return total_cost\n```\n## Gradient descent code implementation\n$$\\begin{align*} \\text{repeat}&\\text{ until convergence:} \\; \\lbrace \\newline\n\\;  w &= w -  \\alpha \\frac{\\partial J(w,b)}{\\partial w} \\tag{3}  \\; \\newline\n b &= b -  \\alpha \\frac{\\partial J(w,b)}{\\partial b}  \\newline \\rbrace\n\\end{align*}$$\nwhere, parameters $w$, $b$ are updated simultaneously.\nThe gradient is defined as:\n$$\n\\begin{align}\n\\frac{\\partial J(w,b)}{\\partial w}  &= \\frac{1}{m} \\sum\\limits_{i = 0}^{m-1} (f_{w,b}(x^{(i)}) - y^{(i)})x^{(i)} \\tag{4}\\\\\n  \\frac{\\partial J(w,b)}{\\partial b}  &= \\frac{1}{m} \\sum\\limits_{i = 0}^{m-1} (f_{w,b}(x^{(i)}) - y^{(i)}) \\tag{5}\\\\\n\\end{align}\n$$\n\nHere *simultaniously* means that you calculate the partial derivatives for all the parameters before updating any of\nthe parameters.\n\nWe will implement GD algorithm for **one** feature. We need three functions:\n\n - `compute_gradient` implementing equation (4) and (5) above\n - `compute_cost` implementing equation (2) above (code from previous lab)\n - `gradient_descent`, utilizing compute_gradient and compute_cost\n\n ```python\n def compute_gradient(x, y, w, b):\n    m = x.shape[0]\n    dj_dw = 0\n    dj_db = 0\n\n    for i in range(m):\n        f_wb = w * x[i] + b\n        dw_dw_i = (f_wb - y[i]) * x[i]\n        dj_db_i = (f_wb - y[i])\n\n        dj_db += dj_db_i\n        dj_dw += dj_dw_i\n    dj_dw = dj_dw / m\n    dj_db = dj_db / m\n\n    return dj_dw, dj_db\n```\n\n![](plot1.png)\n\nAbove, the left plot shows $\\frac{\\partial J(w,b)}{\\partial w}$ or the slope of the cost curve relative to $w$ at three points. On the right side of the plot, the derivative is positive, while on the left it is negative. Due to the 'bowl shape', the derivatives will always lead gradient descent toward the bottom where the gradient is zero.\n\nThe left plot has fixed $b=100$. Gradient descent will utilize both $\\frac{\\partial J(w,b)}{\\partial w}$ and $\\frac{\\partial J(w,b)}{\\partial b}$ to update parameters. The 'quiver plot' on the right provides a means of viewing the gradient of both parameters. The arrow sizes reflect the magnitude of the gradient at that point. The direction and slope of the arrow reflects the ratio of $\\frac{\\partial J(w,b)}{\\partial w}$ and $\\frac{\\partial J(w,b)}{\\partial b}$ at that point.\nNote that the gradient points *away* from the minimum. Review equation (3) above. The scaled gradient is *subtracted* from the current value of $w$ or $b$. This moves the parameter in a direction that will reduce cost.\n\n\nNow that gradients can be computed,  gradient descent, described in equation (3) above can be implemented below in `gradient_descent`.\n\n```python\ndef gradient_descent(x, y, w_in, b_in, alpha, num_iters, cost_function, gradient_function):\n    J_history = []\n    p_history = []\n    b = b_in\n    w = w_in\n\n    for i in range(num_iters):\n        dj_dw, dj_db = gradient_function(x, y, w, b)\n\n        b = b - alpha * dj_db\n        w = w - alpha * dj_dw\n\n        if i<100000:\n            J_history.append(cost_function(x, y, w, b))\n            p.history_append([w,b])\n\n        if i%math.ceil(num_iters/10) ==0:\n            print(f\"Iteration {i:4}: Cost {J_history[-1]:0.2e} \",\n                  f\"dj_dw: {dj_dw: 0.3e}, dj_db: {dj_db:0.3e} \",\n                  f\"w: {w:0.3e}, b:{b:0.5e}\")\n\n    return w, b, J_history, p_history\n```\n\n## Training with GD\n```python\n# initialize parameters\nw_init = 0\nb_init = 0\n# some gradient descent settings\niterations = 10000\ntmp_alpha = 1.0e-2\n# run gradient descent\nw_final, b_final, J_hist, p_hist = gradient_descent(x_train ,y_train, w_init, b_init, tmp_alpha,\n                                                    iterations, compute_cost, compute_gradient)\nprint(f\"(w,b) found by gradient descent: ({w_final:8.4f},{b_final:8.4f})\")\n```\n\nTake a look at the training process by running this code. You will notice that $dj_dw$\nand $dj_db$ get smaller, rapidly at first and then more slowly.\nAs the process nears the 'bottom of the bowl' progress is slower due to the smaller value of the derivative at that point.\n\n\nNow that you have discovered the optimal values for the parameters $w$ and $b$, you can now use the model to predict\nhousing values based on our learned parameters. As expected, the predicted values are nearly the same as the training\nvalues for the same housing. Further, the value not in the prediction is in line with the expected value.\n\n```python\nprint(f\"1000 sqft house prediction {w_final*1.0 + b_final:0.1f} Thousand dollars\")\nprint(f\"1200 sqft house prediction {w_final*1.2 + b_final:0.1f} Thousand dollars\")\nprint(f\"2000 sqft house prediction {w_final*2.0 + b_final:0.1f} Thousand dollars\")\n```\n\nI we take a look at the progress of gradient descent during its execution by plotting the cost over iterations on a contour plot of the cost(w,b), we will see:\n\n![](plot2.png)\n\nAbove, the contour plot shows the $cost(w,b)$ over a range of $w$ and $b$. Cost levels are represented by the rings. Overlayed, using red arrows, is the path of gradient descent. Here are some things to note:\n- The path makes steady (monotonic) progress toward its goal.\n- initial steps are much larger than the steps near the goal\n\n","srcMarkdownNoYaml":"\n\nGradient Descent is a method for unconstrained math optimization. It is a **first order**\niterative algorithm for minimizing differentiable multivariate function.\nThe key idea is to take repeated steps in the opposite direction of the gradient of the function at the current point,\nbecause this is a direction of steepest descent. --> Conversely, stepping in the direction of\nthe gradient will lead to a trajectory that maximizes that function, the procedure is\nthen know as **gradient ascent**\n\n![](gd.jpeg){width=1200px}\n\nIn this tutorial we will automate the process of optimizing $w$ and $b$ usig gradient descent\n\n\n```python\nimport math, copy\nimport numpy as np\nimport matplotlib.pyplot as plt\n```\n\n## Problem Statement\n\nLet's use the same two data points as before - a house with 1000 square feet sold for \\\\$300,000 and a house with 2000 square feet sold for \\\\$500,000.\n\n| Size (1000 sqft)     | Price (1000s of dollars) |\n| ----------------| ------------------------ |\n| 1               | 300                      |\n| 2               | 500                      |\n\n\n```python\nx_train = np.array([1.0, 2.0])\ny_train = np.array([300.0, 500.0])\n```\n\n## Define cost function\nWe consider a linear model that predicts $f_{w,b}(x^{(i)})$:\n$$f_{w,b}(x^{(i)}) = wx^{(i)} + b \\tag{1}$$\nIn linear regression, we utilize input training data to fit the parameters $w$,$b$ by minimizing\na measure of the error between our predictions $f_{w,b}(x^{(i)})$ and the actual data $y^{(i)}$.\nThe measure is called the $cost$, $J(w,b)$. In training we measure the cost over all of our training\nsamples $x^{(i)},y^{(i)}$\n$$J(w,b) = \\frac{1}{2m} \\sum\\limits_{i = 0}^{m-1} (f_{w,b}(x^{(i)}) - y^{(i)})^2\\tag{2}$$\n\nLet's define cost function described above.\n\n```python\ndef compute_cost(x, y, w, b):\n    m = x.shape[0]\n    cost = 0\n\n    for i in range(m):\n        f_wb = w * x[i] + b\n        cost = cost + (f_wb - y[i])**2\n    total_cost = 1 / (2 * m) * cost\n    return total_cost\n```\n## Gradient descent code implementation\n$$\\begin{align*} \\text{repeat}&\\text{ until convergence:} \\; \\lbrace \\newline\n\\;  w &= w -  \\alpha \\frac{\\partial J(w,b)}{\\partial w} \\tag{3}  \\; \\newline\n b &= b -  \\alpha \\frac{\\partial J(w,b)}{\\partial b}  \\newline \\rbrace\n\\end{align*}$$\nwhere, parameters $w$, $b$ are updated simultaneously.\nThe gradient is defined as:\n$$\n\\begin{align}\n\\frac{\\partial J(w,b)}{\\partial w}  &= \\frac{1}{m} \\sum\\limits_{i = 0}^{m-1} (f_{w,b}(x^{(i)}) - y^{(i)})x^{(i)} \\tag{4}\\\\\n  \\frac{\\partial J(w,b)}{\\partial b}  &= \\frac{1}{m} \\sum\\limits_{i = 0}^{m-1} (f_{w,b}(x^{(i)}) - y^{(i)}) \\tag{5}\\\\\n\\end{align}\n$$\n\nHere *simultaniously* means that you calculate the partial derivatives for all the parameters before updating any of\nthe parameters.\n\nWe will implement GD algorithm for **one** feature. We need three functions:\n\n - `compute_gradient` implementing equation (4) and (5) above\n - `compute_cost` implementing equation (2) above (code from previous lab)\n - `gradient_descent`, utilizing compute_gradient and compute_cost\n\n ```python\n def compute_gradient(x, y, w, b):\n    m = x.shape[0]\n    dj_dw = 0\n    dj_db = 0\n\n    for i in range(m):\n        f_wb = w * x[i] + b\n        dw_dw_i = (f_wb - y[i]) * x[i]\n        dj_db_i = (f_wb - y[i])\n\n        dj_db += dj_db_i\n        dj_dw += dj_dw_i\n    dj_dw = dj_dw / m\n    dj_db = dj_db / m\n\n    return dj_dw, dj_db\n```\n\n![](plot1.png)\n\nAbove, the left plot shows $\\frac{\\partial J(w,b)}{\\partial w}$ or the slope of the cost curve relative to $w$ at three points. On the right side of the plot, the derivative is positive, while on the left it is negative. Due to the 'bowl shape', the derivatives will always lead gradient descent toward the bottom where the gradient is zero.\n\nThe left plot has fixed $b=100$. Gradient descent will utilize both $\\frac{\\partial J(w,b)}{\\partial w}$ and $\\frac{\\partial J(w,b)}{\\partial b}$ to update parameters. The 'quiver plot' on the right provides a means of viewing the gradient of both parameters. The arrow sizes reflect the magnitude of the gradient at that point. The direction and slope of the arrow reflects the ratio of $\\frac{\\partial J(w,b)}{\\partial w}$ and $\\frac{\\partial J(w,b)}{\\partial b}$ at that point.\nNote that the gradient points *away* from the minimum. Review equation (3) above. The scaled gradient is *subtracted* from the current value of $w$ or $b$. This moves the parameter in a direction that will reduce cost.\n\n\nNow that gradients can be computed,  gradient descent, described in equation (3) above can be implemented below in `gradient_descent`.\n\n```python\ndef gradient_descent(x, y, w_in, b_in, alpha, num_iters, cost_function, gradient_function):\n    J_history = []\n    p_history = []\n    b = b_in\n    w = w_in\n\n    for i in range(num_iters):\n        dj_dw, dj_db = gradient_function(x, y, w, b)\n\n        b = b - alpha * dj_db\n        w = w - alpha * dj_dw\n\n        if i<100000:\n            J_history.append(cost_function(x, y, w, b))\n            p.history_append([w,b])\n\n        if i%math.ceil(num_iters/10) ==0:\n            print(f\"Iteration {i:4}: Cost {J_history[-1]:0.2e} \",\n                  f\"dj_dw: {dj_dw: 0.3e}, dj_db: {dj_db:0.3e} \",\n                  f\"w: {w:0.3e}, b:{b:0.5e}\")\n\n    return w, b, J_history, p_history\n```\n\n## Training with GD\n```python\n# initialize parameters\nw_init = 0\nb_init = 0\n# some gradient descent settings\niterations = 10000\ntmp_alpha = 1.0e-2\n# run gradient descent\nw_final, b_final, J_hist, p_hist = gradient_descent(x_train ,y_train, w_init, b_init, tmp_alpha,\n                                                    iterations, compute_cost, compute_gradient)\nprint(f\"(w,b) found by gradient descent: ({w_final:8.4f},{b_final:8.4f})\")\n```\n\nTake a look at the training process by running this code. You will notice that $dj_dw$\nand $dj_db$ get smaller, rapidly at first and then more slowly.\nAs the process nears the 'bottom of the bowl' progress is slower due to the smaller value of the derivative at that point.\n\n\nNow that you have discovered the optimal values for the parameters $w$ and $b$, you can now use the model to predict\nhousing values based on our learned parameters. As expected, the predicted values are nearly the same as the training\nvalues for the same housing. Further, the value not in the prediction is in line with the expected value.\n\n```python\nprint(f\"1000 sqft house prediction {w_final*1.0 + b_final:0.1f} Thousand dollars\")\nprint(f\"1200 sqft house prediction {w_final*1.2 + b_final:0.1f} Thousand dollars\")\nprint(f\"2000 sqft house prediction {w_final*2.0 + b_final:0.1f} Thousand dollars\")\n```\n\nI we take a look at the progress of gradient descent during its execution by plotting the cost over iterations on a contour plot of the cost(w,b), we will see:\n\n![](plot2.png)\n\nAbove, the contour plot shows the $cost(w,b)$ over a range of $w$ and $b$. Cost levels are represented by the rings. Overlayed, using red arrows, is the path of gradient descent. Here are some things to note:\n- The path makes steady (monotonic) progress toward its goal.\n- initial steps are much larger than the steps near the goal\n\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":true,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"markdown"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"wrap","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":true,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","highlight-style":"atom-one","toc":true,"css":["../../styles.css"],"include-in-header":["../../fonts.html"],"output-file":"index.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.8.25","theme":{"light":"cosmo","dark":"darkly"},"code-copy":true,"smooth-scroll":true,"title-block-banner":true,"title":"Gradient Descent, how does it work?","author":"Darkhan Islam","date":"2024-10-26","categories":["theory","code"],"image":"gd.gif","listing":{"categories":true,"contents":"posts","type":"grid","sort":"date desc","fields":["image","title","date","categories","description","reading-time"],"feed":true,"filter-ui":true},"page-layout":"article"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}